{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6617b871-bc54-4b35-b714-5e5e7b1401b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting folium\n",
      "  Using cached folium-0.20.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting branca>=0.6.0 (from folium)\n",
      "  Using cached branca-0.8.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from folium) (3.1.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from folium) (1.26.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in /opt/anaconda3/lib/python3.12/site-packages (from folium) (2022.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2>=2.9->folium) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->folium) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->folium) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->folium) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->folium) (2025.1.31)\n",
      "Using cached folium-0.20.0-py2.py3-none-any.whl (113 kB)\n",
      "Using cached branca-0.8.1-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: branca, folium\n",
      "Successfully installed branca-0.8.1 folium-0.20.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install folium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a1d433-e73f-43a5-b6f4-f629d5d20679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EV PERFORMANCE ANALYSIS\n",
      "============================================================\n",
      "Analysis Date: 2025-08-29 00:28\n",
      "Project: EV Industry Market Intelligence\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import folium\n",
    "from folium.plugins import HeatMap, MarkerCluster\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Advanced plotting configuration\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style(\"whitegrid\")\n",
    "color_palette = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "\n",
    "print(\"EV PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"Project: EV Industry Market Intelligence\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3693b8f-a4a6-48b3-a8b0-33d9e21adfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /Users/evanfu/Documents/Personal Projects/EV Performance Analysis/ev-performance-analysis\n",
      "vehicles: 48 rows × 17 columns\n",
      "stations: 19,915 rows × 30 columns\n",
      "sales: 80 rows × 12 columns\n",
      "\n",
      "All datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def load_ev_datasets():\n",
    "    \"\"\"Enhanced data loading with comprehensive validation\"\"\"\n",
    "    \n",
    "    # Navigate to project root\n",
    "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
    "        os.chdir('..')\n",
    "    \n",
    "    print(f\"Working Directory: {os.getcwd()}\")\n",
    "    \n",
    "    # Find latest data files - Updated pattern for charging stations\n",
    "    file_patterns = {\n",
    "        'vehicles': 'data/raw/epa_vehicles_20250829.csv',\n",
    "        'stations': 'data/raw/charging_stations_*_20250829.csv',  # Added wildcard for CA\n",
    "        'sales': 'data/raw/ev_sales_data_20250829.csv'\n",
    "    }\n",
    "    \n",
    "    datasets = {}\n",
    "    file_info = {}\n",
    "    \n",
    "    for name, pattern in file_patterns.items():\n",
    "        files = sorted(glob.glob(pattern))\n",
    "        if not files:\n",
    "            print(f\"No {name} files found matching {pattern}\")\n",
    "            continue\n",
    "            \n",
    "        latest_file = files[-1]\n",
    "        file_info[name] = latest_file\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(latest_file)\n",
    "            if df.empty:\n",
    "                print(f\"{name}: Empty dataset\")\n",
    "                continue\n",
    "            \n",
    "            datasets[name] = df\n",
    "            print(f\"{name}: {len(df):,} rows × {len(df.columns)} columns\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"{name}: Loading error - {e}\")\n",
    "    \n",
    "    return datasets, file_info\n",
    "\n",
    "# Load datasets\n",
    "datasets, file_info = load_ev_datasets()\n",
    "required_datasets = ['vehicles', 'stations', 'sales']\n",
    "if not all(dataset in datasets for dataset in required_datasets):\n",
    "    print(\"\\nCritical datasets missing. Please run data collection script first.\")\n",
    "    print(\"Run: python src/data_collection.py\")\n",
    "else:\n",
    "    vehicles_df = datasets['vehicles'].copy()\n",
    "    stations_df = datasets['stations'].copy()\n",
    "    sales_df = datasets['sales'].copy()\n",
    "    print(f\"\\nAll datasets loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a82b362-03c6-4bed-b3e6-19855f29c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DATA QUALITY ASSESSMENT: EPA VEHICLES\n",
      "----------------------------------------\n",
      "Shape: (48, 17)\n",
      "Memory usage: 0.02 MB\n",
      "No missing values\n",
      "Duplicate rows: 0\n",
      "\n",
      "Numeric columns: 10\n",
      "  year: [2019.0, 2024.0], mean=2021.5\n",
      "  city_mpg: [67.0, 150.0], mean=109.3\n",
      "  highway_mpg: [61.0, 135.0], mean=98.3\n",
      "  combined_mpg: [64.0, 142.0], mean=103.8\n",
      "  range_miles: [237.0, 387.0], mean=327.1\n",
      "  battery_capacity_kwh: [60.0, 135.0], mean=92.6\n",
      "  charge_time_240v: [8.3, 18.8], mean=12.9\n",
      "  msrp_base: [39838.0, 60622.0], mean=49766.9\n",
      "  co2_emissions: [0.0, 0.0], mean=0.0\n",
      "  ghg_score: [10.0, 10.0], mean=10.0\n",
      "\n",
      "Categorical columns: 7\n",
      "  make: 6 unique values\n",
      "  model: 8 unique values\n",
      "  drive_type: 3 unique values\n",
      "  fuel_type: 1 unique values\n",
      "  vehicle_class: 2 unique values\n",
      "\n",
      "DATA QUALITY ASSESSMENT: CHARGING STATIONS\n",
      "----------------------------------------\n",
      "Shape: (19915, 30)\n",
      "Memory usage: 23.46 MB\n",
      "\n",
      "Missing values:\n",
      "  street_address: 3 (0.0%)\n",
      "  facility_type: 15,973 (80.2%)\n",
      "  connector_types: 3 (0.0%)\n",
      "  pricing: 17,009 (85.4%)\n",
      "  hours: 1,568 (7.9%)\n",
      "  date_last_confirmed: 55 (0.3%)\n",
      "  station_phone: 1,158 (5.8%)\n",
      "  owner_type: 15,581 (78.2%)\n",
      "  federal_agency: 19,683 (98.8%)\n",
      "  open_date: 99 (0.5%)\n",
      "  cards_accepted: 18,132 (91.0%)\n",
      "  bd_blends: 19,915 (100.0%)\n",
      "  hydrogen_standards: 19,915 (100.0%)\n",
      "  maximum_vehicle_class: 17,073 (85.7%)\n",
      "  intersection_directions: 13,012 (65.3%)\n",
      "  plus4: 19,915 (100.0%)\n",
      "Duplicate rows: 0\n",
      "\n",
      "Numeric columns: 8\n",
      "  latitude: [32.5, 42.0], mean=35.7\n",
      "  longitude: [-124.3, -114.6], mean=-119.8\n",
      "  level1_count: [0.0, 54.0], mean=0.0\n",
      "  level2_count: [0.0, 338.0], mean=2.7\n",
      "  dc_fast_count: [0.0, 120.0], mean=0.8\n",
      "  bd_blends: [nan, nan], mean=nan\n",
      "  hydrogen_standards: [nan, nan], mean=nan\n",
      "  plus4: [nan, nan], mean=nan\n",
      "\n",
      "Categorical columns: 22\n",
      "  station_name: 19419 unique values\n",
      "  street_address: 11013 unique values\n",
      "  city: 825 unique values\n",
      "  state: 1 unique values\n",
      "  zip_code: 1277 unique values\n",
      "\n",
      "DATA QUALITY ASSESSMENT: EV SALES\n",
      "----------------------------------------\n",
      "Shape: (80, 12)\n",
      "Memory usage: 0.02 MB\n",
      "No missing values\n",
      "Duplicate rows: 0\n",
      "\n",
      "Numeric columns: 9\n",
      "  year: [2019.0, 2025.0], mean=2021.8\n",
      "  month: [1.0, 12.0], mean=6.3\n",
      "  total_ev_sales: [3920.0, 8453.0], mean=5876.1\n",
      "  tesla_sales: [2012.0, 5519.0], mean=3505.4\n",
      "  other_premium_sales: [506.0, 1395.0], mean=868.0\n",
      "  mass_market_sales: [520.0, 2316.0], mean=1200.1\n",
      "  market_share_percent: [1.0, 8.0], mean=4.7\n",
      "  avg_price: [36796.0, 63329.0], mean=51010.3\n",
      "  incentives_total: [5051.0, 11890.0], mean=7859.5\n",
      "\n",
      "Categorical columns: 3\n",
      "  date: 80 unique values\n",
      "  month_name: 12 unique values\n",
      "  quarter: 4 unique values\n"
     ]
    }
   ],
   "source": [
    "def assess_data_quality(df, name):\n",
    "    \"\"\"Comprehensive data quality assessment\"\"\"\n",
    "    print(f\"\\nDATA QUALITY ASSESSMENT: {name.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Missing values\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"\\nMissing values:\")\n",
    "        for col in missing[missing > 0].index:\n",
    "            pct = (missing[col] / len(df)) * 100\n",
    "            print(f\"  {col}: {missing[col]:,} ({pct:.1f}%)\")\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "    \n",
    "    # Duplicates\n",
    "    duplicates = df.duplicated().sum()\n",
    "    print(f\"Duplicate rows: {duplicates:,}\")\n",
    "    \n",
    "    # Numeric columns analysis\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(f\"\\nNumeric columns: {len(numeric_cols)}\")\n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                print(f\"  {col}: [{df[col].min():.1f}, {df[col].max():.1f}], mean={df[col].mean():.1f}\")\n",
    "    \n",
    "    # Categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(f\"\\nCategorical columns: {len(categorical_cols)}\")\n",
    "        for col in categorical_cols[:5]:  # Show first 5\n",
    "            unique_count = df[col].nunique()\n",
    "            print(f\"  {col}: {unique_count} unique values\")\n",
    "\n",
    "# Assess all datasets\n",
    "if 'vehicles_df' in globals():\n",
    "    assess_data_quality(vehicles_df, \"EPA Vehicles\")\n",
    "    assess_data_quality(stations_df, \"Charging Stations\") \n",
    "    assess_data_quality(sales_df, \"EV Sales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4d40df-d222-447e-b85c-b03f2fa65e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
